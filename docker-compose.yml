version: '3.8'
services:
  subgen:
    container_name: subgen4
    tty: true
    image: mccloud/subgen
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    environment:
       - "WHISPER_MODEL=medium-v3"           # Fits 6GB GPU
       - "WHISPER_THREADS=2"                  # Safe threads for RAM & VRAM
       - "PROCADDEDMEDIA=True"                # Skip files with existing subtitles
       - "PROCMEDIAONPLAY=False"
       - "NAMESUBLANG=en"
       - "SKIPIFINTERNALSUBLANG=eng"
       - "WEBHOOKPORT=9000"
       - "CONCURRENT_TRANSCRIPTIONS=1"       # Bazarr sends one file at a time
       - "WORD_LEVEL_HIGHLIGHT=False"         # Saves VRAM
       - "DEBUG=True"
       - "USE_PATH_MAPPING=False"
       - "TRANSCRIBE_DEVICE=cuda"             # GPU transcription
       - "CLEAR_VRAM_ON_COMPLETE=True"        # Frees VRAM after each file
       - "MODEL_PATH=/data/whisper/mccloud/subgen/models"
       - "UPDATE=True"
       - "APPEND=False"
       - "USE_MODEL_PROMPT=False"
       - "CUSTOM_MODEL_PROMPT="
       - "LRC_FOR_AUDIO_FILES=True"
       - "CUSTOM_REGROUP=cm_sl=84_sl=42++++++1"
       - "CHUNK_AUDIO_MAX_SEC=600"           # split audio into 10-min chunks
       - "CHUNK_AUDIO_OVERLAP_SEC=5"         # small overlap for context
    volumes:
       - "${APPDATA}/subgen/models:/data/whisper/mccloud/subgen/models"
       - "./subgen.env:/subgen/subgen.env:ro"  # optional for Bazarr integration
    ports:
       - "9000:9000"
